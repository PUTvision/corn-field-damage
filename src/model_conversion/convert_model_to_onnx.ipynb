{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa9d02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import segmentation_models_pytorch as smp\n",
    "import numpy as np\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eda2982",
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU_DEVICE = 'cpu'\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# DEVICE = 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb1ed11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/media/przemek/ubuntu18/home/przemek/Projects/pp/corn-field-damage/src')\n",
    "import model_training_v2.common.dataset_preparation as dataset_preparation\n",
    "import model_training_v2.common.corn_dataset as corn_dataset\n",
    "import model_training_v2.common.model_definition as model_definition\n",
    "import model_training_v2.common.model_training_results as model_training_results\n",
    "import model_training_v2.common.model_training as model_training\n",
    "import model_training_v2.common.plot_graphs as plot_graphs\n",
    "\n",
    "\n",
    "from importlib import reload \n",
    "reload(dataset_preparation)\n",
    "reload(corn_dataset)\n",
    "reload(model_definition)\n",
    "reload(model_training_results)\n",
    "reload(model_training)\n",
    "reload(plot_graphs)\n",
    "\n",
    "\n",
    "dataset_preparation.init_seeds(778)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3b0ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193c8f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TILES_BASE_DIR = '/media/data/local/corn/new/tiles_stride_768/'\n",
    "TILE_SIZE = 512\n",
    "\n",
    "# BASE_OUTPUT_DIR = '/tmp/aaa/out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f552d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e3dbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = model_definition.ModelType.UNET_PLUS_PLUS__EFFICIENT_NET_B3\n",
    "\n",
    "is_ndvi = False\n",
    "image_channels = 1 if is_ndvi else 3\n",
    "model, model_params = model_definition.get_model_with_params(model_type, in_channels=image_channels, tile_size=TILE_SIZE)\n",
    "\n",
    "print(f'model_params = {model_params}')\n",
    "# print(model)\n",
    "\n",
    "\n",
    "MODEL_PATH = '/media/przemek/dane/local/corn/out/from_drive/model_UNET_PLUS_PLUS__EFFICIENT_NET_B3__big_lr_as_always/model.zip'\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model.eval()\n",
    "print(model)\n",
    "\n",
    "# model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d975179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de9e46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_TILE_PATH = '/home/przemek/Desktop/corn/model/example_tile.png'\n",
    "img_bgr = cv2.imread(EXAMPLE_TILE_PATH)\n",
    "img = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "# img = img_bgr\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770af2c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2711f96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_img = img.astype('float32')\n",
    "prepared_img /= 255\n",
    "prepared_img = prepared_img.transpose(2, 0, 1)  # TODO check\n",
    "                          \n",
    "    \n",
    "input_batch = torch.Tensor(prepared_img).unsqueeze(0)  # aka torch.tensor(img)[np.newaxis, :, :]\n",
    "print(input_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134c9e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model_output = model(input_batch)\n",
    "    \n",
    "predicted_mask_damage = model_output[0][1].numpy() * 255\n",
    "plt.imshow(predicted_mask_damage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfb0b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91bf7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e81dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20672ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, inputs, output_dir / 'keypoints_detector.onnx', opset_version=15, input_names=['input'],\n",
    "                      output_names=['confidence', 'std', 'coords'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063079dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_swish(memory_efficient=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0976dbe1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ONNX_MPDEL_FILE_PATH = '/home/przemek/Desktop/corn/model/corn_segmentation_model.onnx'\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(model,               # model being run\n",
    "                  input_batch,                 # model input (or a tuple for multiple inputs)\n",
    "                  ONNX_MPDEL_FILE_PATH,   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=16,          # the ONNX version to export the model to\n",
    "#                   do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input_rgb_512x512'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b143722",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd04015",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch_numpy = input_batch.numpy()\n",
    "input_batch_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed0475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as rt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a8d2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = rt.InferenceSession(ONNX_MPDEL_FILE_PATH)\n",
    "input_name = sess.get_inputs()[0].name\n",
    "input_name\n",
    "pred_onx = sess.run(None, {input_name: input_batch_numpy})\n",
    "damaged_area_onnx = pred_onx[0][0][1] * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e40ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(damaged_area_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5341185",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONNX_MPDEL_FILE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bddd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "modelonnx = onnx.load(ONNX_MPDEL_FILE_PATH)\n",
    "for input in modelonnx.graph.input:\n",
    "    print (input.name, end=\": \")\n",
    "    # get type of input tensor\n",
    "    tensor_type = input.type.tensor_type\n",
    "    # check if it has a shape:\n",
    "    if (tensor_type.HasField(\"shape\")):\n",
    "        # iterate through dimensions of the shape:\n",
    "        for d in tensor_type.shape.dim:\n",
    "            # the dimension may have a definite (integer) value or a symbolic identifier or neither:\n",
    "            if (d.HasField(\"dim_value\")):\n",
    "                print (d.dim_value, end=\", \")  # known dimension\n",
    "            elif (d.HasField(\"dim_param\")):\n",
    "                print (d.dim_param, end=\", \")  # unknown dimension with symbolic name\n",
    "            else:\n",
    "                print (\"?\", end=\", \")  # unknown dimension with no name\n",
    "    else:\n",
    "        print (\"unknown rank\", end=\"\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
